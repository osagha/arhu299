# Lecture Notes

### [Day 1](day1.qmd): Intro, Text Encoding, Features, Classification
### [Day 2](day2.qmd): Binary classification with hand-crafted features
### [Day 3](day3.qmd): Learning bag-of-words features
### [Day 4](day4.qmd): TFIDF encoding, part 1
### 2/8 - Day 5 - [Notebook 0](https://colab.research.google.com/drive/1A16ttyJ98jkkyLO9mRBYRQy8GzJayEi8?usp=sharing): Intro to Python
### 2/13 - Day 6 - [Notebook 1](https://colab.research.google.com/drive/1UxZzV2AQEO7WPJCpCejVSTwfHfecpILm?usp=sharing) More Python basics
### 2/15 - Day 7 - [Notebook 2](https://colab.research.google.com/drive/10vKFAOS5gdbj1EbgmnPRTPNo1Lm3ycIp?usp=sharing) Intro to PyTorch

### 2/20 - Day 8 - [Notebook 3](https://colab.research.google.com/drive/12kbg0ly1QhTaDLiojdP_v6OK1O5aSXWN?usp=sharing) - [Lecture Notes](day8.qmd)

### 3/7 - [Notebook 4](https://colab.research.google.com/drive/1EakCmkZNo-4DFe73198vgpkWNyNrqpVj?usp=sharing)

### 3/14 - [Notebook 5](https://colab.research.google.com/drive/1njkg1EulZZG3ohqmAZOYIrFIyN6SciAb?usp=sharing)

### 3/26 - see Notebook 5

### 3/28 - Language Models - see [Chapter 3](https://web.stanford.edu/~jurafsky/slp3/3.pdf) of Jurafsky and Martin *Speech and Language Processing* ([full book here](https://web.stanford.edu/~jurafsky/slp3/))

### 4/2 - Language Models (theory) continued

### 4/4-11 - n-gram models in Python [Notebook 6](https://colab.research.google.com/drive/15nwt1Bj7F7LktUlf6HYtbtk-QcP5M01i?usp=sharing)

### 4/16-25 - transformer: word embeddings, positional embeddings, and attention - see [Chapter 10](https://web.stanford.edu/~jurafsky/slp3/10.pdf)

More resources on transformer language models:
3blue1brown videos on transformers: [part 1, on GPT](https://www.youtube.com/watch?v=wjZofJX0v4M), [part 2, on attention](https://www.youtube.com/watch?v=eMlx5fFNoYc)
Andrej Karpathy's [GPT from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY)