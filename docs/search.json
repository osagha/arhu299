[
  {
    "objectID": "pages/lecturenotes/day2.html",
    "href": "pages/lecturenotes/day2.html",
    "title": "Day 2",
    "section": "",
    "text": "Today we’ll discuss feature representations for text. We’ll make embeddings for text documents using a bag-of-words representation. Then we’ll write down a pen-and-paper neural network for sentiment analysis, then build it in a spreadsheet."
  },
  {
    "objectID": "pages/lecturenotes/day2.html#content",
    "href": "pages/lecturenotes/day2.html#content",
    "title": "Day 2",
    "section": "",
    "text": "Today we’ll discuss feature representations for text. We’ll make embeddings for text documents using a bag-of-words representation. Then we’ll write down a pen-and-paper neural network for sentiment analysis, then build it in a spreadsheet."
  },
  {
    "objectID": "pages/lecturenotes/index.html",
    "href": "pages/lecturenotes/index.html",
    "title": "Lecture Notes",
    "section": "",
    "text": "Lecture Notes\n\nDay 1"
  },
  {
    "objectID": "pages/syllabus.html",
    "href": "pages/syllabus.html",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "Syllabus for ARHU299: Machine Learning in Language and Art at the University of Maryland, College Park.\nLast updated January 24, 2024.\nInstructor: Omar Agha (oagha@umd.edu)\nTA: Utku Türk (utkuturk@umd.edu)\nOffice hours: TBD (please fill out the When2Meet here)\n\n\nIn this course, you will learn how machine learning models read and write text, classify images, and more. This requires understanding some basic elements of linear algebra (vectors and matrices), calculus (the chain rule for derivatives), Python programming, and basic statistics. If you have not seen any of this before, you will learn the relevant tools along the way, in the context of solving applied problems, and with the aid of software that performs complex calculations for you.\nThis is a fast-paced class. There will be homework every week, and frequent in-class assignments. You will need to make a serious effort to learn about difficult technical topics. I assume you are here because you want to learn this material, and I will do everything I can to help you succeed.\nWe will work up from simple models to more complex ones. We will start with the simplest neural network architecture, the perceptron, and apply it to text classification tasks. After that, we will study deeper networks (multi layer perceptrons) that can be used for language modeling (predicting the next word).\nBy the end of the course, we will cover the basics of transformer models and convolutional neural networks. Transformers are the building blocks of language models like GPT, and convolutional NNs are used for classifying and generating images. Depending on the speed of your progress, we might also have time to discuss more advanced neural network architectures like latent diffusion models, which are behind powerful text-to-image generators like Stable Diffusion and Midjourney.\n\n\n\nEngineers and scientists who work on these topics usually do years of intense study in math and computer science before reaching proficiency. So it’s not realistic for us to go that deep in one semester.\nLuckily, building simple text and image models (and maybe music generators) does not require as much expertise, only some Python skills and enough curiosity to figure things out on one’s own.\n\n\n\nYou will learn how to multiply matrices, use probability, and understand simple equations and graphs involving functions like \\(\\sin\\), \\(\\cos\\), and \\(\\log\\). You will see how these concepts are actually applied in real-world problems.\nMachine learning models use calculus (derivatives) under the hood, and you will learn the basics of how this works. But for the most part. we will rely on software to do those calculations for us.\n\n\n\nYou will learn how to use the Python programming language, along with some Python libraries. The most important libraries are PyTorch and Numpy, for matrix math, and Pandas, for data processing. We will also use Matplotlib, Seaborn, and Plotly for plotting, and Pillow for image processing.\nThe basic Python concepts you will learn are functions, classes, lists, tuples, dictionaries, for-loops, list comprehensions, and lambda expressions.\nIf you want to get a head start on your Python journey, google all the unfamiliar terms in this section and read up.\n\n\n\nThere is no textbook, since I haven’t found one that fits the audience of this course. I will post optional resources (books, articles, and videos) in the lecture notes, and under the Resources section of the course website.\n\n\n\nI will post lecture notes within 48 hours after the relevant lecture. Lecture notes will usually not be available before class, so you must pay attention and take your own notes during class sessions.\nAll lecture notes will be posted under Lecture Notes. I will also post code in the form of Python Notebooks on the website. You can open a copy in Google Colab to study and play with the code.\n\n\n\n\n\nI will assume that you are here because you want to learn. This applies to all policies and requirements: I assume that you will come to class and complete the homework because you want to learn.\nI will do my best to not waste your time, and to not impose any requirements on you that are unnecessary for your educational goals.\n\n\n\nAttendance is not directly graded. However, there will be frequent in-class assignments, and participation is a part of your grade. Also, missing class will make it hard to keep up. For this reason, poor attendance will generally lower your grade and prevent you from learning effectively.\n\n\n\nIn this class you will learn math, programming, and critical thinking skills by practicing them. Learning this material without practice is not possible.\nI find that accepting late homework usually causes more students to fall behind, ultimately harming their grades and progress, even if it feels generous in the short term. So, late homework will not be accepted unless I have already granted you an extension.\nWe will mostly be coding in Google Colab. If you want to use another editor you can, but your submitted code must be in .ipynb format and it must run correctly in Colab. (So, make sure to upload your file in Colab and test it there.)\n\n\n\nIf you need an extension on any assignment, contact me before noon on the due date, and verify that I approve. (Better to reach out earlier than that if possible.)\nIf you need to be excused from class, contact me before that class starts.\nIf you are excused from class, I will let you know if there are any in-class assignments that you need to make up.\n\n\n\nThe UMD Code of Academic Integrity defines plagiarism as “representing the words or ideas of another as one’s own in any academic course, exercise or research”. If you copy text or code from any source, you must treat is as a quotation and provide the source. (You can either link to the source or provide a full bibliographic citation.)\nPlagiarism on any assignment will result in a zero. Repeat plagiarists will be reported to the Office of Student Conduct.\nCopying work from another student is plagiarism, but group work is encouraged. All submitted work must be your own.\n\n\n\nGenerative “AI” tools like ChatGPT or Bing produce text in a random process by sampling from the most likely next words.\nThey can be useful in certain contexts. However, the randomly generated text is often biased and false in subtle ways, and plagiarized from other sources. (This is because the model’s next-word-probabilities are derived from documents scraped from the internet.)\nCopying and pasting the output of generative AI on any assignment will be considered plagiarism. (See the above definition.)\nIf you choose to use generative AI to help with solving problems, that’s ok, but you must ensure that all submitted work is your own, and you are responsible for any errors. (Using ChatGPT or other software to edit your prose is also ok, especially if you are not a native speaker of English.)\n\n\n\n\n\n\n\n50% homework\n20% quizzes\n10% participation (in person and on Discord)\n20% project proposal\n\n\n\n\n\nBy the last day of class, please submit a 2-3 page project proposal. This can be for a product that you would like to create, or for a research project. In the proposal, please discuss in detail\n\nhow you would use the technologies we cover in class, (5%)\nwhat you think the most challenging components would be, (5%)\nwhat the likely social impact of the project would be. (5%)\n\nYou don’t need to turn in any working code. (You are welcome to do so, and you won’t be graded on the code, only the proposal.)\n\n\nBefore Mar 14, please schedule a meeting with me to talk through project ideas.\n\nMar 14: Turn in one paragraph on your project proposal. If you have multiple ideas, do a short paragraph for each.\nApr 11: Turn in a half page, more fleshed out version. Start to include some details about technologies, challenges, and/or social impact. (Worth 5% out of the full 20%.)\nMay 7: Final due date for project proposal.\n\n\n\n\n\n\n\nYour success is very important to me. I (or the TA) will answer your emails promptly (within 24 hours) and make time to meet with you if you need extra help.\nIf you need help, please contact me ASAP. Often, students fail because they wait too long to ask for help, and then fall too far behind to catch up. Don’t let this happen to you!\n\n\n\nIf you find yourself struggling to understand something, try re-reading the lecture notes or re-watching the assigned videos. Ideas often take multiple tries to click.\nI will link to helpful videos and articles in my lecture notes. Don’t forget to use them!\n\n\n\nGroup work is highly encouraged. Please try to find a study group early on, and try to meet up for each homework. I’ll make a Discord chat for the class to help you all collaborate. As a reminder, copying code or prose directly from other students is plagiarism, so please make sure that all submitted work is your own.\n\n\n\nTaking care of yourself is the foundation for all success in life. Make sure you come to class well-rested, nourished, and ready to learn. (If you need to eat or drink beverages in class, that’s fine with me.)\n\n\n\nIf mental health challenges are keeping you from doing your best, the university provides Counseling and Behavioral Health Services. The earlier you reach out, the more you can benefit from these resources.\n\n\n\n\nStudents with disabilities are very welcome in this class. If you require accommodations, please contact me as soon as possible. For more information about disability accommodations at UMD, please see the ADS webpage."
  },
  {
    "objectID": "pages/syllabus.html#course-summary",
    "href": "pages/syllabus.html#course-summary",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "In this course, you will learn how machine learning models read and write text, classify images, and more. This requires understanding some basic elements of linear algebra (vectors and matrices), calculus (the chain rule for derivatives), Python programming, and basic statistics. If you have not seen any of this before, you will learn the relevant tools along the way, in the context of solving applied problems, and with the aid of software that performs complex calculations for you.\nThis is a fast-paced class. There will be homework every week, and frequent in-class assignments. You will need to make a serious effort to learn about difficult technical topics. I assume you are here because you want to learn this material, and I will do everything I can to help you succeed.\nWe will work up from simple models to more complex ones. We will start with the simplest neural network architecture, the perceptron, and apply it to text classification tasks. After that, we will study deeper networks (multi layer perceptrons) that can be used for language modeling (predicting the next word).\nBy the end of the course, we will cover the basics of transformer models and convolutional neural networks. Transformers are the building blocks of language models like GPT, and convolutional NNs are used for classifying and generating images. Depending on the speed of your progress, we might also have time to discuss more advanced neural network architectures like latent diffusion models, which are behind powerful text-to-image generators like Stable Diffusion and Midjourney."
  },
  {
    "objectID": "pages/syllabus.html#how-deep-will-we-go",
    "href": "pages/syllabus.html#how-deep-will-we-go",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "Engineers and scientists who work on these topics usually do years of intense study in math and computer science before reaching proficiency. So it’s not realistic for us to go that deep in one semester.\nLuckily, building simple text and image models (and maybe music generators) does not require as much expertise, only some Python skills and enough curiosity to figure things out on one’s own."
  },
  {
    "objectID": "pages/syllabus.html#math-skills",
    "href": "pages/syllabus.html#math-skills",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "You will learn how to multiply matrices, use probability, and understand simple equations and graphs involving functions like \\(\\sin\\), \\(\\cos\\), and \\(\\log\\). You will see how these concepts are actually applied in real-world problems.\nMachine learning models use calculus (derivatives) under the hood, and you will learn the basics of how this works. But for the most part. we will rely on software to do those calculations for us."
  },
  {
    "objectID": "pages/syllabus.html#programming-skills",
    "href": "pages/syllabus.html#programming-skills",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "You will learn how to use the Python programming language, along with some Python libraries. The most important libraries are PyTorch and Numpy, for matrix math, and Pandas, for data processing. We will also use Matplotlib, Seaborn, and Plotly for plotting, and Pillow for image processing.\nThe basic Python concepts you will learn are functions, classes, lists, tuples, dictionaries, for-loops, list comprehensions, and lambda expressions.\nIf you want to get a head start on your Python journey, google all the unfamiliar terms in this section and read up."
  },
  {
    "objectID": "pages/syllabus.html#resources",
    "href": "pages/syllabus.html#resources",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "There is no textbook, since I haven’t found one that fits the audience of this course. I will post optional resources (books, articles, and videos) in the lecture notes, and under the Resources section of the course website."
  },
  {
    "objectID": "pages/syllabus.html#lecture-notes",
    "href": "pages/syllabus.html#lecture-notes",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "I will post lecture notes within 48 hours after the relevant lecture. Lecture notes will usually not be available before class, so you must pay attention and take your own notes during class sessions.\nAll lecture notes will be posted under Lecture Notes. I will also post code in the form of Python Notebooks on the website. You can open a copy in Google Colab to study and play with the code."
  },
  {
    "objectID": "pages/syllabus.html#class-policies",
    "href": "pages/syllabus.html#class-policies",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "I will assume that you are here because you want to learn. This applies to all policies and requirements: I assume that you will come to class and complete the homework because you want to learn.\nI will do my best to not waste your time, and to not impose any requirements on you that are unnecessary for your educational goals.\n\n\n\nAttendance is not directly graded. However, there will be frequent in-class assignments, and participation is a part of your grade. Also, missing class will make it hard to keep up. For this reason, poor attendance will generally lower your grade and prevent you from learning effectively.\n\n\n\nIn this class you will learn math, programming, and critical thinking skills by practicing them. Learning this material without practice is not possible.\nI find that accepting late homework usually causes more students to fall behind, ultimately harming their grades and progress, even if it feels generous in the short term. So, late homework will not be accepted unless I have already granted you an extension.\nWe will mostly be coding in Google Colab. If you want to use another editor you can, but your submitted code must be in .ipynb format and it must run correctly in Colab. (So, make sure to upload your file in Colab and test it there.)\n\n\n\nIf you need an extension on any assignment, contact me before noon on the due date, and verify that I approve. (Better to reach out earlier than that if possible.)\nIf you need to be excused from class, contact me before that class starts.\nIf you are excused from class, I will let you know if there are any in-class assignments that you need to make up.\n\n\n\nThe UMD Code of Academic Integrity defines plagiarism as “representing the words or ideas of another as one’s own in any academic course, exercise or research”. If you copy text or code from any source, you must treat is as a quotation and provide the source. (You can either link to the source or provide a full bibliographic citation.)\nPlagiarism on any assignment will result in a zero. Repeat plagiarists will be reported to the Office of Student Conduct.\nCopying work from another student is plagiarism, but group work is encouraged. All submitted work must be your own.\n\n\n\nGenerative “AI” tools like ChatGPT or Bing produce text in a random process by sampling from the most likely next words.\nThey can be useful in certain contexts. However, the randomly generated text is often biased and false in subtle ways, and plagiarized from other sources. (This is because the model’s next-word-probabilities are derived from documents scraped from the internet.)\nCopying and pasting the output of generative AI on any assignment will be considered plagiarism. (See the above definition.)\nIf you choose to use generative AI to help with solving problems, that’s ok, but you must ensure that all submitted work is your own, and you are responsible for any errors. (Using ChatGPT or other software to edit your prose is also ok, especially if you are not a native speaker of English.)"
  },
  {
    "objectID": "pages/syllabus.html#grades",
    "href": "pages/syllabus.html#grades",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "50% homework\n20% quizzes\n10% participation (in person and on Discord)\n20% project proposal"
  },
  {
    "objectID": "pages/syllabus.html#project-proposal",
    "href": "pages/syllabus.html#project-proposal",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "By the last day of class, please submit a 2-3 page project proposal. This can be for a product that you would like to create, or for a research project. In the proposal, please discuss in detail\n\nhow you would use the technologies we cover in class, (5%)\nwhat you think the most challenging components would be, (5%)\nwhat the likely social impact of the project would be. (5%)\n\nYou don’t need to turn in any working code. (You are welcome to do so, and you won’t be graded on the code, only the proposal.)\n\n\nBefore Mar 14, please schedule a meeting with me to talk through project ideas.\n\nMar 14: Turn in one paragraph on your project proposal. If you have multiple ideas, do a short paragraph for each.\nApr 11: Turn in a half page, more fleshed out version. Start to include some details about technologies, challenges, and/or social impact. (Worth 5% out of the full 20%.)\nMay 7: Final due date for project proposal."
  },
  {
    "objectID": "pages/syllabus.html#how-to-succeed-in-this-class",
    "href": "pages/syllabus.html#how-to-succeed-in-this-class",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "Your success is very important to me. I (or the TA) will answer your emails promptly (within 24 hours) and make time to meet with you if you need extra help.\nIf you need help, please contact me ASAP. Often, students fail because they wait too long to ask for help, and then fall too far behind to catch up. Don’t let this happen to you!\n\n\n\nIf you find yourself struggling to understand something, try re-reading the lecture notes or re-watching the assigned videos. Ideas often take multiple tries to click.\nI will link to helpful videos and articles in my lecture notes. Don’t forget to use them!\n\n\n\nGroup work is highly encouraged. Please try to find a study group early on, and try to meet up for each homework. I’ll make a Discord chat for the class to help you all collaborate. As a reminder, copying code or prose directly from other students is plagiarism, so please make sure that all submitted work is your own.\n\n\n\nTaking care of yourself is the foundation for all success in life. Make sure you come to class well-rested, nourished, and ready to learn. (If you need to eat or drink beverages in class, that’s fine with me.)\n\n\n\nIf mental health challenges are keeping you from doing your best, the university provides Counseling and Behavioral Health Services. The earlier you reach out, the more you can benefit from these resources."
  },
  {
    "objectID": "pages/syllabus.html#disability-accommodations",
    "href": "pages/syllabus.html#disability-accommodations",
    "title": "ARHU299 Syllabus",
    "section": "",
    "text": "Students with disabilities are very welcome in this class. If you require accommodations, please contact me as soon as possible. For more information about disability accommodations at UMD, please see the ADS webpage."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ARHU299",
    "section": "",
    "text": "This is the homepage for ARHU299: Machine Learning in Language and Art at the University of Maryland, College Park.\nPlease see the syllabus for more info."
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Resources",
    "section": "",
    "text": "I’ll be adding resources here throughout the semester.\n\n\n\n\nA tried-and-true standard textbook for computational linguistics and NLP. The book’s website includes slides too, which are great for a quick reference. Accompanying Youtube lectures can be found here.\n\n\n\nA high quality, detailed, and somewhat technical introduction to NLP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA brilliant visual introduction to deep learning by 3blue1brown (Grant Sanderson). See also his interactive courses on neural networks, linear algebra, and calculus.\n\n\n\n\n\n\nA Stanford NLP course by Dan Jurafsky, based on the textbook Speech and Language Processing linked above. More accessible than the other courses listed below.\n\n\n\nA Stanford course by Christopher Manning, free on Youtube. This is aimed at Computer Science majors, so it may be more accessible after you have already learned the basics in this course.\n\n\n\nA UC Berkeley course on computer vision, free on Youtube. Quite technical, and best approached after this class."
  },
  {
    "objectID": "pages/resources.html#textbooks",
    "href": "pages/resources.html#textbooks",
    "title": "Resources",
    "section": "",
    "text": "A tried-and-true standard textbook for computational linguistics and NLP. The book’s website includes slides too, which are great for a quick reference. Accompanying Youtube lectures can be found here.\n\n\n\nA high quality, detailed, and somewhat technical introduction to NLP."
  },
  {
    "objectID": "pages/resources.html#videos",
    "href": "pages/resources.html#videos",
    "title": "Resources",
    "section": "",
    "text": "A brilliant visual introduction to deep learning by 3blue1brown (Grant Sanderson). See also his interactive courses on neural networks, linear algebra, and calculus."
  },
  {
    "objectID": "pages/resources.html#full-courses",
    "href": "pages/resources.html#full-courses",
    "title": "Resources",
    "section": "",
    "text": "A Stanford NLP course by Dan Jurafsky, based on the textbook Speech and Language Processing linked above. More accessible than the other courses listed below.\n\n\n\nA Stanford course by Christopher Manning, free on Youtube. This is aimed at Computer Science majors, so it may be more accessible after you have already learned the basics in this course.\n\n\n\nA UC Berkeley course on computer vision, free on Youtube. Quite technical, and best approached after this class."
  },
  {
    "objectID": "pages/lecturenotes/day1.html",
    "href": "pages/lecturenotes/day1.html",
    "title": "Day 1",
    "section": "",
    "text": "A neural network is a kind of function. It can take inputs in array format, and return outputs in a (possibly different) array format.\nNeural networks can take many kinds of inputs, like text, images, or sound files. In each case, the input has to be encoded as an array of numbers.\n\n\n\n\nflowchart LR\n    A(Text) --&gt; Z{Neural network}\n    B(Image) --&gt; Z\n    C(Sound file) --&gt; Z\n    Z --&gt; D(\"Label (Classification)\")\n    Z --&gt; E(\"Text, Image, Sound (Generation)\")\n    \n\n\n\n\n\nIn the case of classification, the output is a label. In the case of generation, the output could be of many types, including more text, images, or sound.\n\n\n\nOn a computer, all text is an encoded sequence of characters. A character is a symbol like a letter or number, punctuation, spaces/tabs/newlines, or special characters like “?”” or emojis.\nUnicode is the global standard for text encoding. It assigns every character to a code point. For example, capital A is U+0041, lowercase a is U+0061, and the number 1 is U+0031. Unicode covers all symbols in all scripts, plus many other characters. Some other examples are below.\n\n\n\nSymbol\nCode point\n\n\n\n\n⽔\nU+2F54\n\n\n(Space)\nU+0020\n\n\nअ\nU+0905\n\n\n?\nU+003F\n\n\n\nYou can search for any symbol you like here and find its Unicode code point.\nCode points are turned into machine-readable representations by particular encoding schemes, which differ in how much memory they use. The most popular is UTF-8 (read more about this on the Wiki link).\n\n\n\nLet’s take text classification as an example. In class we talked about sentiment analysis, spam detection, and topic modeling, but there are many other subtypes too.\n\n\n\n\nflowchart TD\n    A(Text Classification) --- B(Sentiment analysis)\n    A --- C(Spam detection)\n    A --- D(Topic modeling)\n    A --- E(...)\n\n\n\n\n\nIn text classification, the input is a string (a sequence of characters). Let’s take sentiment analysis as an example.\n\n\n\n\nflowchart LR\n    A(\"Text string &lt;br&gt; `This movie was great`\") --&gt; Z{Neural network}\n    Z --&gt; D(\"Positive ✓\")\n    Z --&gt; E(\"Negative ✗\")\n\n\n\n\n\nIn sentiment analysis, a model takes in a string and outputs a label, either positive or negative.\nIn practice, the model is rarely 100% sure about the label, so it outputs probabilities. For example, if 'This movie was great.' is the input, the model might output 0.9 for positive and 0.1 for negative.\nNext class, we’ll see a worked out example with a simple toy model.\n\n\nIf we’re doing text classification in English, then the vocabulary would consist of all English words (in the dictionary, let’s say).\nEach word in the vocabulary is just a sequence of characters, as far as the computer is concerned. It doesn’t know that dog is more similar in meaning to canine than it is to philosophy—all it sees are the characters.\nWe need a feature representation of words that captures similarities and differences in meaning. So, we encode every word as a vector, a list of numbers. These numbers can be thought of as coordinates for points in a high-dimensional space.\nNo matter how many dimensions a vector space has, we can always calculate the distance between points in the space.\n\n\n\nThe job of vector space embedding is to assign coordinates to every word in the vocabulary, and do this so that similar words are relatively close together and dissimilar words are relatively far apart.\nTo see an example, here are some 200 dimensional word embeddings that have been projected down into 3 dimensions. (Think about shadow puppets: 3D objects project as 2D shadows on a flat surface. This is kind of like looking at 3D shadows of 200D points.)\nYou can zoom and pan around and look at which words are closer together.\n\n\n\n\nNext class, we will see a toy example of text classification with low-dimensional feature representations of strings. From there, we will look at how higher-dimensional feature representations help models understand more about the meaning of the text."
  },
  {
    "objectID": "pages/lecturenotes/day1.html#what-is-a-neural-network-conceptually",
    "href": "pages/lecturenotes/day1.html#what-is-a-neural-network-conceptually",
    "title": "Day 1",
    "section": "",
    "text": "A neural network is a kind of function. It can take inputs in array format, and return outputs in a (possibly different) array format.\nNeural networks can take many kinds of inputs, like text, images, or sound files. In each case, the input has to be encoded as an array of numbers.\n\n\n\n\nflowchart LR\n    A(Text) --&gt; Z{Neural network}\n    B(Image) --&gt; Z\n    C(Sound file) --&gt; Z\n    Z --&gt; D(\"Label (Classification)\")\n    Z --&gt; E(\"Text, Image, Sound (Generation)\")\n    \n\n\n\n\n\nIn the case of classification, the output is a label. In the case of generation, the output could be of many types, including more text, images, or sound."
  },
  {
    "objectID": "pages/lecturenotes/day1.html#what-is-text",
    "href": "pages/lecturenotes/day1.html#what-is-text",
    "title": "Day 1",
    "section": "",
    "text": "On a computer, all text is an encoded sequence of characters. A character is a symbol like a letter or number, punctuation, spaces/tabs/newlines, or special characters like “?”” or emojis.\nUnicode is the global standard for text encoding. It assigns every character to a code point. For example, capital A is U+0041, lowercase a is U+0061, and the number 1 is U+0031. Unicode covers all symbols in all scripts, plus many other characters. Some other examples are below.\n\n\n\nSymbol\nCode point\n\n\n\n\n⽔\nU+2F54\n\n\n(Space)\nU+0020\n\n\nअ\nU+0905\n\n\n?\nU+003F\n\n\n\nYou can search for any symbol you like here and find its Unicode code point.\nCode points are turned into machine-readable representations by particular encoding schemes, which differ in how much memory they use. The most popular is UTF-8 (read more about this on the Wiki link)."
  },
  {
    "objectID": "pages/lecturenotes/day1.html#text-classification",
    "href": "pages/lecturenotes/day1.html#text-classification",
    "title": "Day 1",
    "section": "",
    "text": "Let’s take text classification as an example. In class we talked about sentiment analysis, spam detection, and topic modeling, but there are many other subtypes too.\n\n\n\n\nflowchart TD\n    A(Text Classification) --- B(Sentiment analysis)\n    A --- C(Spam detection)\n    A --- D(Topic modeling)\n    A --- E(...)\n\n\n\n\n\nIn text classification, the input is a string (a sequence of characters). Let’s take sentiment analysis as an example.\n\n\n\n\nflowchart LR\n    A(\"Text string &lt;br&gt; `This movie was great`\") --&gt; Z{Neural network}\n    Z --&gt; D(\"Positive ✓\")\n    Z --&gt; E(\"Negative ✗\")\n\n\n\n\n\nIn sentiment analysis, a model takes in a string and outputs a label, either positive or negative.\nIn practice, the model is rarely 100% sure about the label, so it outputs probabilities. For example, if 'This movie was great.' is the input, the model might output 0.9 for positive and 0.1 for negative.\nNext class, we’ll see a worked out example with a simple toy model.\n\n\nIf we’re doing text classification in English, then the vocabulary would consist of all English words (in the dictionary, let’s say).\nEach word in the vocabulary is just a sequence of characters, as far as the computer is concerned. It doesn’t know that dog is more similar in meaning to canine than it is to philosophy—all it sees are the characters.\nWe need a feature representation of words that captures similarities and differences in meaning. So, we encode every word as a vector, a list of numbers. These numbers can be thought of as coordinates for points in a high-dimensional space.\nNo matter how many dimensions a vector space has, we can always calculate the distance between points in the space.\n\n\n\nThe job of vector space embedding is to assign coordinates to every word in the vocabulary, and do this so that similar words are relatively close together and dissimilar words are relatively far apart.\nTo see an example, here are some 200 dimensional word embeddings that have been projected down into 3 dimensions. (Think about shadow puppets: 3D objects project as 2D shadows on a flat surface. This is kind of like looking at 3D shadows of 200D points.)\nYou can zoom and pan around and look at which words are closer together."
  },
  {
    "objectID": "pages/lecturenotes/day1.html#for-next-time",
    "href": "pages/lecturenotes/day1.html#for-next-time",
    "title": "Day 1",
    "section": "",
    "text": "Next class, we will see a toy example of text classification with low-dimensional feature representations of strings. From there, we will look at how higher-dimensional feature representations help models understand more about the meaning of the text."
  },
  {
    "objectID": "pages/lecturenotes/day3.html",
    "href": "pages/lecturenotes/day3.html",
    "title": "Day 3",
    "section": "",
    "text": "Today we’ll talk about learning word embeddings from data."
  },
  {
    "objectID": "pages/lecturenotes/day3.html#content",
    "href": "pages/lecturenotes/day3.html#content",
    "title": "Day 3",
    "section": "",
    "text": "Today we’ll talk about learning word embeddings from data."
  }
]